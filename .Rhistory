source("corr.R")
source("complete.R")
cr <- corr("specdata", 150)
head(cr)
## [1] -0.01896 -0.14051 -0.04390 -0.06816 -0.12351 -0.07589
summary(cr)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
## -0.2110 -0.0500  0.0946  0.1250  0.2680  0.7630
cr <- corr("specdata", 400)
head(cr)
## [1] -0.01896 -0.04390 -0.06816 -0.07589  0.76313 -0.15783
summary(cr)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
## -0.1760 -0.0311  0.1000  0.1400  0.2680  0.7630
cr <- corr("specdata", 5000)
summary(cr)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
##
length(cr)
## [1] 0
cr <- corr("specdata")
summary(cr)
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
## -1.0000 -0.0528  0.1070  0.1370  0.2780  1.0000
length(cr)
## [1] 323
source("http://d396qusza40orc.cloudfront.net/rprog%2Fscripts%2Fsubmitscript1.R")
subit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
submit()
q()
x <- 1:10
if(x > 5) {
x <- 0
}
q()
set.seed(1)
rpois(5, 2)
?rnorm
?split
source('~/github/R Programming/cachevector.R')
makeVector
makeVector()
get()
makevector(5)
a <- makeVector(5)
a
a.get()
get()
get(a)
get(4)
cachemean(a)
cachemean(a)
cachemean(a)
m
?inverse
?inv
?invert
a$get()
makeVector(c(1,2,3))
b <- makeVector(c(1,2,3))
b$get
b$get()
cachemean(b)
cachemean(b)
A <- c(c(0,1),c(1,0))
A
dim(A)
str(A)
c <- rbind(c(1, -1/4), c(-1/4, 1))
solve(c)
c %*% solve(c)
?solve
source('~/github/ProgrammingAssignment2/cachematrix.R')
x <- matrix(data=c,nrow=3,ncol=3)
c=1:9
x <- matrix(data=c,nrow=3,ncol=3)
x
makeCacheMatrix(x)
source('~/github/ProgrammingAssignment2/cachematrix.R')
c=1:9
x <- matrix(data=c,nrow=3,ncol=3)
solve(x)
c=c(1:8,10)
x <- matrix(data=c,nrow=3,ncol=3)
solve(x)
a <- makeCacheMatrix(x)
a$get
a$get()
a$get() == x
cacheSolve(a)
cacheSolve(a)
source('~/github/ProgrammingAssignment2/cachematrix.R')
source('~/github/ProgrammingAssignment2/cachematrix.R')
source('~/github/ProgrammingAssignment2/cachematrix.R')
source('~/github/ProgrammingAssignment2/cachematrix.R')
c=c(1:8,10)
x <- matrix(data=c,nrow=3,ncol=3)
a <- makeCacheMatrix(x)
a$get() == x
cacheSolve(a)
cacheSolve(a)
q()
?ppois
library(datasets)
Rprof()
fit <- lm(y ~ x1 + x2)
Rprof(NULL)
fit <- lm(y ~ x1 + x2)
?set.seed
source('~/github/ProgrammingAssignment2/cachematrix.R')
c=c(1:399,10)
x <- matrix(data=c,nrow=20,ncol=20)
b <- solve(x)
c <- rnorm(400)
x <- matrix(data=c,nrow=20,ncol=20)
b <- solve(x)
c <- rnorm(40000)
x <- matrix(data=c,nrow=200,ncol=200)
b <- solve(x)
?system.time
system.time(solve(x))
c <- rnorm(4000000)
x <- matrix(data=c,nrow=2000,ncol=2000)
system.time(solve(x))
a <- makeCacheMatrix(x)
a$get == x
d <- a$get
d <- a$get()
system.time(cacheSolve(a))
system.time(cacheSolve(a))
clear()
cls()
system.time('http://jhsph.edu')
system.time(readLines('http://jhsph.edu'))
?svd
q()
install.packages("rmysql")
install.packages("RMySQL")
source("http://bioconductor.org/biocLite.R")
biocLite("rhdf5")
biocLite("rhdf5")
D = h5read("getdata-data-h5ex_d_extern.h5","/")
source(rhdf5)
library(rhdf5)
D = h5read("getdata-data-h5ex_d_extern.h5","/")
D = h5read("getdata-data-h5ex_d_extern.h5")
h5ls("getdata-data-h5ex_d_extern.h5")
D = h5read("getdata-data-h5ex_d_extern.h5","DS1")
D
D <- h5read("getdata-data-h5ex_d_extern.h5","DS1")
sum(D)
sum(as.numeric(D))
sum(as.numeric(D[,]))
sum(as.numeric(D[,]))
D
as.numeric(D)
D[,1]
?sapply
sapply(D,sum)
sum(D[,1])
D[,1]
D
as.numeric(D[,1])
sum(as.numeric(D[,1]))
h5ls("getdata-data-h5ex_d_extern.h5")
h5read("getdata-data-h5ex_d_extern.h5","DS1")
con = url('http://biostat.jhsph.edu/~jleek/contact.html')
htmlCode = readLines(con)
close(con)
htmlCode
htmlCode[10]
?nchar
nchar(htmlCode[10])
nchar(htmlCode[20])
nchar(htmlCode[30])
nchar(htmlCode[100])
q()
con = url('https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for')
htmlCode = readLines(con)
close(con)
read.fwf('getdata-wksst8110.for')
?read.fwf
lengt(h03JAN1990)
length(h03JAN1990)
length('h03JAN1990')
b <- 'h03JAN1990'
length(b)
?length
nchars(b)
nchar(b)
nchar('     23.4-0.4     25.1-0.3     26.6 0.0     28.6 0.3')
12+52
sum(c(12, 7,4, 9,4, 9,4, 9,4))
nchar('03JAN1990     ')
nchar('10JAN1990     23.4-0.8     25.2-0.3     26.6 0.1     28.6 0.3')
?split
sapply(c('10JAN1990     ','23.4'),nchar)
sapply(c('10JAN1990     ','23.4','-0.8    ','25,2','-0.3     ','26,6',' 0.1     ','28,6',' 0.3'),nchar)
bla <- sapply(c('10JAN1990     ','23.4','-0.8    ','25,2','-0.3     ','26,6',' 0.1     ','28,6',' 0.3'),nchar)
bla
bla[,2]
bla[,1]
?read.fwf
read.fwf('getdata-wksst8110.for',bla)
data <- read.fwf('getdata-wksst8110.for',bla)
data[,4]
head(data)
head(data[,1])
head(data[2,])
head(data[,2])
?strsplit
strsplit('10JAN1990     23.4-0.8     25.2-0.3     26.6 0.1     28.6 0.3')
strsplit('10JAN1990     23.4-0.8     25.2-0.3     26.6 0.1     28.6 0.3',' ')
b <- strsplit('10JAN1990     23.4-0.8     25.2-0.3     26.6 0.1     28.6 0.3',' ')
b[6])
b[6]
b[[1]]
b <- b[[1]]
b[6]
b[11]
head(data)
head(data[5,])
head(data[5,1])
head(data[5,2])
head(data[5,4])
bla
?read.fwf
data <- read.fwf('getdata-wksst8110.for',skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4))
head(data)
head[data[8,]]
head[data[8]]
head(data[8,])
head(data[,8])
tosum <- as.numeric(data[,8])
sum(tosum)
source('~/github/R Programming/oauth demo.R')
?oauth_app
source('~/github/R Programming/oauth demo.R')
install.packages("httpuv")
source('~/github/R Programming/oauth demo.R')
head(data)
head(data[6,])
head(data[,6])
tosum <- as.numeric(data[,6])
sum(tosum)
tosum <- as.numeric(data[,8])
sum(tosum)
data <- read.fwf('getdata-wksst8110.for',skip=4,widths=c(12, 7,4, 9,4, 9,4, 9,4))
tosum <- as.numeric(data[,8])
sum(tosum)
tosum <- as.numeric(data[,6])
sum(tosum)
tosum <- as.numeric(data[,8])
tosum2 <- as.numeric(data[,9])
sum(tosum) + sum(tosum2)
source('~/github/R Programming/helper.R')
source('~/github/R Programming/helper.R')
helper()
numeric()
source('~/github/R Programming/helper.R')
helper()
summed
source('~/github/R Programming/helper.R')
helper()
source('~/github/R Programming/helper.R')
helper()
summed
source('~/github/R Programming/helper.R')
s <- helper()
s
q()
gdpdata <- read.csv('gdpdata.csv',skip = 4)
head(gdpdata)
edudata <- read.csv('edudata.csv')
head(edudata)
gdpdata[191,]
gdpdata[190,]
gdpdata[192,]
gdp2 <- gdpdata[1:190]
gdp2 <- gdpdata[1:190,]
gdpdata[194,]
mergeddata <- merge(gdpdata, edudata, by.x = 'X', by.y = 'CountryCode')
?arrange
library("plyr", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
?arrange
mergeddata <- merge(gdp2, edudata, by.x = 'X', by.y = 'CountryCode')
head(gdp2)
arrange(gdp2, X.1)
as.numeric(gdp2$X.1)
gdp2$X.1
?as.integer
as.integer(gdp2$X.1)
bla <- gdp2$X.1
head(bla)
arrange(gdp2, X.1)
gdp3 <- gdp2
gdp3$X.1 <- as.integer(gdp3$X.1)
arrange(gdp3, gdp3$X.1)
gdp3 <- gdp2
gdp3$X.1 <- as.integer(levels(gdp3$X.1))
levels(gdp3$X.1)
?read.csv
gdpdata <- read.csv('gdpdata.csv', skip = 4, as.is = TRUE)
head(gdpdata)
gdpdata[191]
gdpdata[191,]
gdp2 <- gdpdata[1:190,]
tail(gdp2)
head(as.numeric(gdp2$X.1))
gdp2$X.1 <- as.numeric(gdp2$X.1)
arrange(gdp2, X.1)
stringsAsFactors
edudata <- read.csv('edudata.csv', as.is = TRUE)
mergeddata <- merge(gdp2, edudata, by.x = 'X.1', by.y = 'CountryCode')
edudata$CountryCode
gdp2$X.1
gdp2$X
mergeddata <- merge(gdp2, edudata, by.x = 'X', by.y = 'CountryCode')
head(edudata)
?subset
highoecd <- subset(mergeddata, Income.Group == 'High income: OECD')
highnonoecd <- subset(mergeddata, Income.Group == 'High income: nonOECD')
highoecd$X.1
mean(highoecd$X.1)
mean(highnonoecd$X.1)
189/5
?quantile
?ddply
dim(mergeddata$X.1)
mergeddata$X.1
dim(as.numeric(mergeddata$X.1))
str(mergeddata$X.1)
arrange(mergeddata, X.1)
head(mergeddata$X.1)
arrangeddata <- arrange(mergeddata, X.1)
head(arrangeddata$X.1)
topquintile <- arrangeddata[1:38,]
topquintile$Income.Group
topquintile$Income.Group == 'Lower middle income'
as.integer(topquintile$Income.Group == 'Lower middle income')
sum(as.integer(topquintile$Income.Group == 'Lower middle income'))
?merge
?arrange
arrange(gdp2, desc(X.1))
q()
?print
q()
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv','microdataidaho.csv',method='curl')
data <- read.csv('microdataidaho.csv')
head(data)
names(data)
?strsplit
stuff <- strsplit(names(data),'wgtp')
stuff[123]
download.file('https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv','gdpdata.csv',method='curl')
data <- read.csv('gdpdata.csv')
head(data)
data <- read.csv('gdpdata.csv', skip = 4)
head(data)
?paste
?grep
head(data$X.4)
options(stringsAsFactors = FALSE)
data <- read.csv('gdpdata.csv', skip = 4)
head(data)
head(data$X.4)
sub(',','',data$X.4)
head(data$X.4)
sub('\,','',data$X.4)
sub(',','','a,b')
sub(',', '', data$X.4)
data$X.4 <- gsub(',', '', data$X.4)
?avg
?average
?mean
mean(data$X.4)
mean(as.numeric(data$X.4))
mean(as.numeric(data$X.4), na.rm=TRUE)
head(data$X.4)
?mean
data$X.4
head(data)
data2 <- read.csv('gdpdata.csv')
head(data2)
data
gdps <- data$X.4[1,192]
gdps <- data$X.4[1:192]
tail(gdps)
gdps <- gdps[1:190]
mean(as.numeric(gdps))
?grep
head(data)
data[1:2]
data[,1:2]
data[1:2,]
data <- data[1:190,]
tail(data)
grep("^United",data$X.3)
grep("^United",data$X.3), 3
?merge
gdpdata <- data
edudata <- read.csv('edudata.csv')
head(edudata)
head(gdpdata)
?merge
mergeddata <- merge(gdpdata, edudata, by.x = X, by.y = CountryCode)
mergeddata <- merge(gdpdata, edudata, by.x = 'X', by.y = 'CountryCode')
head(mergeddata)
head(data2)
head(edudata)
grep('[jJ]une',edudata)
edudata[10,]
edudata[,10]
head(edudata[,10])
head(edudata)
grep('[jJ]une',edudata$special.notes)
grep('[jJ]une',edudata$Special.Notes)
len([1,2,3,4])
len(c(1,2,3,4)
len(c(1,2,3,4))
len(c(1,2,3,4))
length(c(1,2,3,4))
bla <- grep('[jJ]une',edudata$Special.Notes)
edudata$Special.Notes[bla]
bla <- grep('[fF]iscal .* [jJ]une',edudata$Special.Notes)
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
install.packages("quantmod")
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
sampleTimes = index(amzn)
head(sampleTimes)
grep("^2012-",sampleTimes)
length(grep("^2012-",sampleTimes))
st2012 <- sampleTimes[grep("^2012-",sampleTimes)]
?wday
install.packages("lubridate")
library("lubridate", lib.loc="/Library/Frameworks/R.framework/Versions/3.0/Resources/library")
wday('2012-12-2')
wday('2012-12-9')
wday('2012-12-4')
mondays <- st2012[wday(st2012)==1]
mondays
st2012
wday(st2012 == 1)
?lapply
lapply(st2012, wday)
sapply(st2012, wday)
sapply(st2012, wday) == 1
sum(sapply(st2012, wday) == 1)
?wday
sum(sapply(st2012, wday) == 2)
getwd()
setwd('/Users/Moritz/github/GettingCleaningPeerAssessment/')
getwd()
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
train <- read.csv('UCI HAR Dataset/train/X_train.txt')
head(train)
?read.table
train <- read.table('UCI HAR Dataset/train/X_train.txt', sep = ' ')
train <- read.table('UCI HAR Dataset/train/X_train.txt', sep = ' ', header = TRUE)
train <- read.table('UCI HAR Dataset/train/X_train.txt', sep = ' ')
train <- read.table('UCI HAR Dataset/train/X_train.txt', sep = ' ')
train2 <- read.table('UCI HAR Dataset/train/X_train.txt', sep = ' ')
train2 <- read.table('UCI HAR Dataset/train/X_train.txt')
head(train)
head(train2)
train_labels <- read.table('UCI HAR Dataset/train/y_train.txt')
head(train_labels)
levels(train_labels)
train_labels <- read.table('UCI HAR Dataset/train/y_train.txt', stringsAsFactors=True)
train_labels <- read.table('UCI HAR Dataset/train/y_train.txt', stringsAsFactors=TRUE)
levels(train_labels)
summary(train_)
summary(train_labels)
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
?append
append(train, train_labels)
append(train2, train_labels)
merged <- append(train2, train_labels)
?merge
totaltrain <- cbind(train2, train_labels)
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
cleandata()
cleandata
cleandata()
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
cleandata()
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
data <- cleandata()
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
head(data)
head(data)
summary(data)
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
source('~/github/GettingCleaningPeerAssessment/run_analysis.R')
q()
